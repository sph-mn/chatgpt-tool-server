# chatgpt tool server example
example setup to let chatgpt run commands on your machine via a self-hosted server.

* only explicitly defined commands in `src/config.js` can be executed
* chatgpt will receive command output
* this setup is for demonstration and doesn't configure authentication

when you interact with your custom gpt and it invokes a tool, the openai servers send a request to your public-facing server. this server forwards the request through a unix socket over an ssh reverse tunnel to your local tool server broker application, which then executes command-line utilities available on your local workstation.

# basic requirements
* a server with a public ip address and ssl certificate
* ssh access from the local machine to the server
* locally installed node.js

# server setup
example configuration for nginx using a unix socket and an existing letsencrypt ssl certificate.

## nginx
```nginx
server {
  listen 443 ssl;
  listen [::]:443 ssl;
  server_name your.domain.example;

  ssl_certificate /etc/letsencrypt/live/your.domain.example/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/your.domain.example/privkey.pem;
  include /etc/letsencrypt/options-ssl-nginx.conf;
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;

  location /broker/ {
    proxy_pass http://unix:/run/http/broker:;
    rewrite ^/broker(/.*)$ $1 break;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto https;
    add_header Access-Control-Allow-Origin "https://your.domain.example" always;
    add_header Access-Control-Allow-Methods "POST, GET, OPTIONS" always;
    add_header Access-Control-Allow-Headers "Content-Type, Authorization" always;
    if ($request_method = OPTIONS) { return 204; }
  }
}
```

## socket path
the socket file needs to be readable and writable by nginx and the ssh-tunnel user on the server.

the solution here is to have both be in the same group "http" and setup the directory so that created files automatically receive the group permissions of the directory.

~~~
install -d -m 2770 -o myusername -g http /run/http
~~~

## sshd
/etc/sshd_config
~~~
AllowTcpForwarding yes
AllowStreamLocalForwarding yes
~~~

listing active configuration
```sh
sshd -T
```

# workstation setup
## create and customize the tool configuration:
```sh
cp src/config.js.example src/config.js
```

* `roots`: Allowed working directories
* `tools`: Available commands (argv or stdin modes)

## start the broker
```sh
./exe/start-broker
```

it will be listening locally on port 12717.

now the broker should be available under `http://127.0.0.1:12717`.

https is not necessary here because traffic will go through the ssh tunnel.

to test a command:
~~~
curl -X POST "http://127.0.0.1/echo_args" -H "Content-Type: application/json" -d '{"keywords": ["test"]}'
~~~

## start the tunnel
```sh
./exe/start-tunnel hostname
```

now the broker should be available under `https://your.domain.example/broker`;

# chatgpt setup
* in the left sidebar, open "GPTs"
* in the top right corner, open "Create"
* click on "Create new Action"
* insert the openapi spec generated by your local broker via https://your.domain.example/broker

# possible issues
* incorrect root passed
  * if the requested root does not exist, the configured command will not be found.
* ssh not allowing forwarding
  * could be something with the sshd config or the socket file permissions